üöÄ Projeto Final ‚Äî Machine Learning & Deep Learning (Aula 01)
Preencha este arquivo seguindo o roteiro abaixo. Use linguagem simples e objetiva. N√£o envie dados grandes para o reposit√≥rio. Coloque links para o dataset e mantenha apenas amostras pequenas se necess√°rio.

1) Identifica√ß√£o do Projeto
T√≠tulo do projeto: Mec√¢nica 
Turma/Disciplina: GTI.3S-2025
Professor: Rodrigo Moreira
Grupo (at√© 5): Nome completo + e-mail/usu√°rio GitHub
Integrante 1 ‚Äî Kaw√£ de Oliveira Pereira RA:116471
Integrante 2 ‚Äî Kaique Gon√ßalves RA:80732
Integrante 3 ‚Äî Nathan de Sousa RA:106774 
Integrante 4 ‚Äî Marvos Douglas Queiroz Freires RA:15363 
Integrante 5 ‚Äî Alan Gomes Ara√∫jo RA:27545

2) A IA mec√¢nica foi desenvolvida para auxiliar em toda a manuten√ß√£o de ve√≠culos e m√°quinas,
identificando falhas com precis√£o por meio de sensores e aprendizado de m√°quina. Ela automatiza diagn√≥sticos,
sugere solu√ß√µes e pode executar reparos simples com bra√ßos rob√≥ticos. Isso reduz custos, aumenta a efici√™ncia e minimiza erros humanos.

3) Defini√ß√£o do Problema
Tema: Manuten√ß√£o de Ve√≠culos e M√°quinas 
Problema (pergunta mensur√°vel): Queremos prever uma forma de ajudar a todos, em qualquer manuten√ß√£o a ser feita sem gastar e ainda ajudando da melhor forma
Objetivo do modelo:Aux√≠lio em Manuten√ß√£o de Ve√≠culos e M√°quinas 
Vari√°veis (entrada/sa√≠da): Texto
Relev√¢ncia/Impacto: Por que √© √∫til? A crescente complexidade dos sistemas mec√¢nicos e eletr√¥nicos em m√°quinas industriais e ve√≠culos modernos exige um n√≠vel elevado de conhecimento t√©cnico para a realiza√ß√£o de manuten√ß√µes corretivas e preventivas.
Ao mesmo tempo, h√° um d√©ficit de profissionais altamente qualificados no setor de manuten√ß√£o, o que impacta diretamente na produtividade, na seguran√ßa e nos custos operacionais.
Nesse contexto, o uso da Intelig√™ncia Artificial como ferramenta de suporte t√©cnico torna-se altamente relevante, pois pode oferecer diagn√≥sticos precisos, sugest√µes de reparo, acompanhamento de manuten√ß√µes preditivas e otimiza√ß√£o do tempo de resposta,
promovendo maior efici√™ncia operacional e redu√ß√£o de falhas cr√≠ticas.

4) Dataset
Fonte e link: UCI Machine Learning Repository ‚Äî AI4I 2020 Predictive Maintenance Dataset.
Descri√ß√£o resumida: #amostras (instances): ~10.000 
UCI Archive
+1

#features: 14 colunas (com vari√°veis cont√≠nuas e categ√≥ricas) 
UCI Archive
+1

Tipo: Tabular / Multivariado; pode ser tratado tamb√©m como s√©ries temporais dependendo de como for organizado.
Tamanho aproximado: 509.9 KB (arquivo CSV)
Licen√ßa: Creative Commons Attribution 4.0 International (CC BY 4.0)
Alvo (target):Colunas de falha (‚Äúmachine failure‚Äù), e falhas espec√≠ficas: TWF (tool wear failure), HDF, PWF, OSF, RNF.
Balanceamento: As classes de falha s√£o desbalanceadas: a grande maioria dos registros representam opera√ß√µes normais, e apenas uma parte relativamente pequena indica falhas.
(Esses datasets de manuten√ß√£o preditiva geralmente t√™m esse perfil)
Como ser√° carregado: Link direto via UCI (‚ÄúDownload CSV‚Äù) 
Reposit√≥rio UCI
+1

Pode ser carregado localmente ou via bibliotecas Python: ex: pandas ler CSV, ou usando bibliotecas de datasets do UCI / ucimlrepo.

5) Estrat√©gia Inicial
Baseline ML:Modelo: Regress√£o Log√≠stica e/ou √Årvore de Decis√£o (Decision Tree)

Por que?

Simples, r√°pida de treinar e f√°cil de interpretar.

Ajuda a identificar rapidamente se o problema √© aprend√≠vel.

Boa para compara√ß√£o com modelos mais complexos posteriormente.

Features usadas:

Vari√°veis b√°sicas como: press√£o, temperatura, vibra√ß√£o, uso acumulado, tempo desde √∫ltima manuten√ß√£o, etc.

Sem engenharia de features inicialmente ‚Äî apenas dados crus e normalizados.
Modelo ML principal: Modelo recomendado: XGBoost ou Random Forest

Justificativa:

XGBoost √© altamente eficaz em dados tabulares com vari√°veis num√©ricas e categ√≥ricas.

Lida bem com valores ausentes, intera√ß√µes n√£o lineares e desbalanceamento (via par√¢metro scale_pos_weight).

Tem desempenho superior em muitos benchmarks industriais.

Random Forest como alternativa mais simples e robusta, √∫til em tuning inicial.

Engenharia de features poss√≠vel:

Tempo at√© pr√≥xima falha (se dispon√≠vel).

M√©dia m√≥vel e desvio padr√£o (janelas temporais).

Frequ√™ncia de uso, varia√ß√£o de sensores, etc.
Deep Learning: Dados tabulares/sequenciais (ex: MetroPT-3)

Modelo sugerido: RNN ou LSTM

Justificativa:

Se os dados estiverem organizados em sequ√™ncia por tempo (ex: sensores por minuto), uma RNN/LSTM pode aprender padr√µes temporais antes da falha.

√ötil para prever falhas iminentes ou tempo at√© falha (Remaining Useful Life).

Alternativa mais simples: MLP (Multilayer Perceptron) para dados agregados ou n√£o temporais.

b) Dados de √°udio (ex: MIMII Dataset)

Modelo sugerido: CNN + LSTM (ou CNN pura com espectrogramas)

Justificativa:

Transformar √°udio em espectrogramas e usar CNNs para extrair padr√µes visuais relacionados a falhas.

Se for sequencial no tempo, usar CNN + LSTM para capturar varia√ß√£o temporal da anomalia.
M√©tricas principais:Problema de classifica√ß√£o bin√°ria (falha vs. normal):

F1-score: Principal m√©trica para balancear precis√£o e recall, especialmente com dados desbalanceados.

AUC-ROC: Avalia o desempenho geral do modelo, independentemente de limiar.

Recall (Sensibilidade): Cr√≠tico para n√£o perder falhas reais (falsos negativos perigosos).

Precision: Tamb√©m importante, especialmente se a√ß√µes de manuten√ß√£o forem caras.

Se o problema for regress√£o (ex: tempo at√© falha):

MAE (Erro Absoluto M√©dio) e RMSE: Para estimativas cont√≠nuas do tempo de falha com penaliza√ß√£o proporcional ao erro.
Crit√©rios de sucesso (meta):F1-score ‚â• 0.85 no conjunto de teste.

Garante que tanto falhas reais est√£o sendo detectadas quanto o n√∫mero de falsos alarmes √© aceit√°vel.

Recall ‚â• 0.90, se seguran√ßa for uma prioridade.

AUC-ROC ‚â• 0.90 indica bom separador entre estados normais e com falha.

Para regress√£o: MAE ‚â§ 5 horas ou similar, dependendo da frequ√™ncia dos dados e criticidade do sistema.

6) Riscos e Considera√ß√µes √âticas
Vi√©s nos dados: Classes desbalanceadas? A maioria dos dados representa situa√ß√µes normais, com poucas amostras de falha (evento raro).

Isso pode fazer com que o modelo tenha tend√™ncia a prever "sem falha", ignorando sinais de alerta.

Risco pr√°tico: falhas reais n√£o detectadas ‚Üí acidentes, perda financeira, danos ao equipamento.

Mitiga√ß√£o: uso de t√©cnicas como SMOTE, reamostragem, pesos ajustados no modelo, e prioriza√ß√£o de recall.
Representatividade? Dados coletados de apenas um tipo de m√°quina ou frota podem n√£o generalizar para outras marcas, ambientes ou condi√ß√µes operacionais.

Risco √©tico: um modelo treinado em contexto X pode falhar silenciosamente em contexto Y, criando uma falsa sensa√ß√£o de seguran√ßa.

Mitiga√ß√£o: treinar com dados de fontes variadas, uso de valida√ß√£o cruzada por dom√≠nio, e testes em ambientes reais antes da implanta√ß√£o.
Privacidade/LGPD: Cont√©m dados pessoais?Os datasets usados (UCI, MIMII, etc.) n√£o cont√™m dados pessoais identific√°veis (nome, CPF, localiza√ß√£o, etc.).

Por√©m, em aplica√ß√µes reais, √© comum que sistemas de manuten√ß√£o estejam integrados com sistemas de gest√£o de frota, condutores ou operadores ‚Üí dados pessoais podem ser inclu√≠dos
(e.g., ID do motorista, hor√°rio de uso, geolocaliza√ß√£o).
Quais cuidados? Garantir anonimiza√ß√£o ou pseudonimiza√ß√£o de qualquer dado pessoal sens√≠vel.

Aplicar princ√≠pios da LGPD:Cont√©m dados pessoais?

Os datasets usados (UCI, MIMII, etc.) n√£o cont√™m dados pessoais identific√°veis (nome, CPF, localiza√ß√£o, etc.).

Por√©m, em aplica√ß√µes reais, √© comum que sistemas de manuten√ß√£o estejam integrados com sistemas de gest√£o de frota, condutores ou operadores ‚Üí dados pessoais podem ser inclu√≠dos (e.g., ID do motorista, hor√°rio de uso, geolocaliza√ß√£o).

Cuidados necess√°rios:

Garantir anonimiza√ß√£o ou pseudonimiza√ß√£o de qualquer dado pessoal sens√≠vel.

Aplicar princ√≠pios da LGPD: finalidade clara, minimiza√ß√£o de dados, seguran√ßa da informa√ß√£o, consentimento (se necess√°rio).

Evitar perfis de operador com base em falhas, para n√£o gerar vi√©s ou discrimina√ß√£o.
Limita√ß√µes conhecidas: Tamanho do dataset:

Alguns datasets (ex: AI4I 2020) s√£o pequenos (~10.000 amostras), o que pode levar √† superajuste (overfitting) e baixa generaliza√ß√£o.

Modelos complexos como deep learning exigem mais dados para serem eficazes.

Ru√≠do e qualidade dos dados:

Dados de sensores podem ter leituras com ru√≠do, falhas de calibra√ß√£o, perda de sinal, etc.

Isso pode afetar o desempenho do modelo e gerar diagn√≥sticos incorretos.

Generaliza√ß√£o limitada:

Modelos treinados em simula√ß√µes ou ambientes laboratoriais nem sempre funcionam bem em cen√°rios reais (ex: clima, carga vari√°vel, operadores diferentes).

Risco pr√°tico: decis√µes erradas de manuten√ß√£o, parada desnecess√°ria ou falhas n√£o previstas.

Interpreta√ß√£o do modelo:

Modelos complexos (ex: XGBoost, CNNs) podem ser ‚Äúcaixas-pretas‚Äù, dificultando a explica√ß√£o da decis√£o.

Em ambientes cr√≠ticos (como manuten√ß√£o de m√°quinas pesadas), a explicabilidade √© essencial para aceita√ß√£o e seguran√ßa.

7) Cronograma (alto n√≠vel)
Aula 01: Problema + Dataset ‚úÖ
Aula 02: EDA + Prepara√ß√£o de dados
Aula 03: Baseline + ML tradicional
Aula 04: DL (rede neural) + compara√ß√£o
Aula 05: Avalia√ß√£o final + Deploy + Apresenta√ß√£o

8) Estrutura do Reposit√≥rio
.
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îú‚îÄ‚îÄ ISSUE_TEMPLATE/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ aula01.yml
‚îÇ   ‚îî‚îÄ‚îÄ PULL_REQUEST_TEMPLATE.md
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/            # dados brutos (n√£o versionar arquivos grandes)
‚îÇ   ‚îî‚îÄ‚îÄ processed/      # dados processados (n√£o versionar arquivos grandes)
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ checklist_aula01.md
‚îÇ   ‚îî‚îÄ‚îÄ relatorio_template.md  # usaremos na entrega final
‚îú‚îÄ‚îÄ notebooks/          # notebooks Colab/Jupyter
‚îú‚îÄ‚îÄ src/                # c√≥digo fonte (fun√ß√µes/utilit√°rios)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ README.md           # este arquivo

9) Como rodar (Local ou Colab)
Colab: Abra notebooks/ e crie um notebook. Use o link do dataset para carregar os dados.
Local (opcional):
python -m venv .venv
source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt

10) Status
 Tema definido
 Problema e objetivo escritos
 Dataset escolhido e validado
 Justificativa conclu√≠da
 Issue ‚ÄúAula 01 ‚Äî Kickoff‚Äù aberta e preenchida

üìå Conven√ß√µes
Nome do reposit√≥rio: mldl-2025-grupoNN-tema-curto (ex.: mldl-2025-grupo03-pneumonia)
N√£o subir arquivos > 50 MB. Para dados grandes, use link externo.
Cada altera√ß√£o relevante deve vir via Pull Request com descri√ß√£o clara.
